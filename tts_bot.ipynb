{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TTS_BOT_PUBLIC.ipynb","provenance":[{"file_id":"1rBSbtWAbsTBXB_jVfzowV06ntFiRe5Pv","timestamp":1599410067466},{"file_id":"1II1uKlq2DPU56uwF5HuuDomcS2wkeRMx","timestamp":1599356453805}],"collapsed_sections":[],"authorship_tag":"ABX9TyPSOnZscg7FodIzYScKlgqh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"swonMxlBCMAh","colab_type":"text"},"source":["# INSTRUCTIONS\n","Register a new chatbot with twitch. https://dev.twitch.tv/console/apps/create\n","\n","Download models and copy them to your Google Drive into a folder named \"tts\".\n","Get current download list of models and current speaker list from here: \n","https://drive.google.com/file/d/1v2o0G5uFOmkVIIou5ZMWhTrOClFjKslP/view?usp=sharing\n","\n","Edit parameters in Part 3. Edit you twitch auth token (https://twitchapps.com/tmi/), your channel, speaker list, and default speaker. \n","\n","Select GPU runtime by menu->runtime->change runtime type->GPU\n","\n","Run code blocks by pressing play arrow at top left corner.\n","\n","**Run Part 1.** This will tell you what GPU colab has given you. The name of the GPU will be on the 4th line of text. Preferably you want a Tesla P100-PCIE. Second best is Tesla T4. If you get Tesla K80 (too slow) Factory restart the runtime (runtime->factory restart runtime) and run Part 1 again. Repeat until you get a better GPU.\n","\n","**Run Part 2.** You will be prompted for auth token to connect your google drive to colab. Click the link and select your google account with the drive. Then copy code (do not use the copy button, it is buggy) and paste into box and press enter. This will install dependencies and copy your models to the colab notebook.  The icon will stop spinning after the code has finished executing. You will see a message that the runtime has crashed, this is intentional so that the runtime resets and the newly installed dependencies can be used.\n","\n","**Run Part 3.** If it's the first run you will see some debug information. You will see \"Receiving messages\" in the output window at bottom of webpage. When a cheer has been detected the audio will be produced and a player will pop up with the message text. The first synthesis of audio will take longer as the models have to be loaded. Set Autoplay_On to False if you want to click the play button instead of automatically playing. If you want you can save the audio by right clicking the player and selecting 'save as'. There is a message queue. If playing automatically the next message will wait for the previous to stop playing.\n","\n","If you get error \"Could not load the JavaScript files needed to display output.\n","This is probably because your Google Account login access has expired or because third-party cookies are not allowed by your browser.\" you will need to relogin to colab.\n","\n","Brower window must not be minimized or a background tab, otherwise audio will not play until you switch to it. Colab runtime will reset automatically after 12hours of use, so you will need to rerun all code afterwards."]},{"cell_type":"code","metadata":{"id":"qm6MvJxldn00","colab_type":"code","colab":{}},"source":["#PART 1\n","!nvidia-smi \n","!nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BPZAEeAaHDYJ","colab_type":"code","colab":{}},"source":["#PART 2\n","\n","#get models from google drive\n","from google.colab import drive\n","drive.mount('/content/drive/', force_remount=True)\n","\n","%cd /content\n","\n","!git clone https://github.com/NVIDIA/tacotron2.git\n","\n","!pip install matplotlib==2.1.0\n","!pip install tensorflow==1.15.2\n","!pip install numpy==1.16.4\n","!pip install inflect==0.2.5\n","!pip install librosa==0.6.0\n","!pip install scipy==1.0.0\n","!pip install Unidecode==1.0.22\n","!pip install pillow\n","!pip install numba==0.48\n","!pip install soundfile\n","!pip install torch==1.4\n","!pip install emoji\n","!pip install pydub\n","\n","%cd /content/tacotron2/\n","!git submodule init\n","!git submodule update\n","\n","%cd /content/tacotron2/waveglow\n","!wget https://raw.githubusercontent.com/NVIDIA/waveglow/master/denoiser.py\n","\n","%cd /content/tacotron2/\n","!cp '/content/drive/My Drive/tts/James_waveglow' '/content/tacotron2/James_waveglow'\n","!cp '/content/drive/My Drive/tts/James_checkpoint' '/content/tacotron2/James_checkpoint'\n","!cp '/content/drive/My Drive/tts/David_waveglow' '/content/tacotron2/David_waveglow'\n","!cp '/content/drive/My Drive/tts/David_checkpoint' '/content/tacotron2/David_checkpoint'\n","\n","exit()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kB5lZTrERKc","colab_type":"code","colab":{}},"source":["#PART 3\n","\n","%cd /content/tacotron2/\n","\n","#PARAMETERS\n","server = 'irc.chat.twitch.tv'\n","port = 6667\n","nickname = 'TTS_BOT'\n","#Get auth token from https://twitchapps.com/tmi/\n","token = 'enter you auth token here'\n","channel = '#yourchannelnamehere'\n","Autoplay_On = True\n","speaker_list = [\"David\", \"James\"]\n","default_speaker = \"David\"\n","\n","import librosa\n","import soundfile as sf\n","import sys\n","sys.path.append('waveglow/')\n","import numpy as np\n","import torch\n","import subprocess\n","import os\n","\n","from hparams import create_hparams\n","from model import Tacotron2\n","from layers import TacotronSTFT, STFT\n","from audio_processing import griffin_lim\n","from train import load_model\n","from text import text_to_sequence\n","from denoiser import Denoiser\n","\n","import socket\n","from emoji import demojize\n","from datetime import datetime\n","import re\n","import time\n","from IPython.display import Audio\n","import IPython.display as ipd\n","from IPython.display import clear_output\n","from IPython.display import HTML\n","from pydub import AudioSegment\n","import time\n","import multiprocessing \n","\n","def parse_resp(resp):\n","  user = message = \"not found\"\n","  re_pattern_user_portion = re.compile(r\"^.+\\s#[_a-zA-Z0-9]+\")\n","  match_user_portion = re_pattern_user_portion.finditer(resp)\n","  for m in match_user_portion:\n","    s = m.start()\n","    e = m.end()\n","    break\n","  user_portion = resp[s:e]\n","  message = demojize(resp[e+2:])\n","  re_pattern_user = re.compile(r\":[_a-zA-Z0-9]+!\")\n","  match_user = re_pattern_user.finditer(user_portion)\n","  for m in match_user:\n","    s = m.start()\n","    e = m.end()\n","    break\n","  user = resp[s+1:e-1]\n","  return user, message\n","\n","def synth_line(s, text):\n","  checkpoint_path = f\"{s}_checkpoint\"\n","  waveglow_path = f\"{s}_waveglow\"                \n","  model = load_model(hparams)\n","  model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n","  _ = model.cuda().eval().half()          \n","\n","  waveglow = torch.load(waveglow_path)['model']\n","  waveglow.cuda().eval().half()\n","  for k in waveglow.convinv:\n","      k.float()\n","  denoiser = Denoiser(waveglow)            \n","  sequence = np.array(text_to_sequence(text, ['english_cleaners']))[None, :]\n","  sequence = torch.autograd.Variable(torch.from_numpy(sequence)).long()\n","  sequence = sequence.cuda()\n","\n","  mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n","\n","  with torch.no_grad():\n","    audio = waveglow.infer(mel_outputs_postnet, sigma=1)\n","\n","  audio_denoised = denoiser(audio, strength=0.02)[:, 0]          \n","  audioout = audio_denoised[0].data.cpu().numpy()\n","  return audioout\n","\n","def receive_resp():\n","  #Create file for queue\n","  if not os.path.exists(\"queue_file\"):\n","    queue = open(\"queue_file\", 'w')\n","    queue.close()\n","\n","  while True:\n","      resp = sock.recv(2048).decode('utf-8')\n","\n","      if resp.startswith('PING'):\n","          sock.send(\"PONG\\n\".encode('utf-8'))\n","      \n","      elif len(resp) > 0:\n","        if \"PRIVMSG\" in resp:\n","          #print(resp)\n","          user, message = parse_resp(resp)\n","\n","          #CHECK IF CHEER WAS MADE\n","          found_cheer = False\n","          found_PogChamp = False\n","          found_Shamrock = False\n","          found_Slade = False\n","          re_pattern_cheer = re.compile(r\"(\\s|^)(c|C)heer[0-9]+(\\s|$)\")\n","          re_pattern_cheer_PogChamp = re.compile(r\"(\\s|^)(p|P)og(c|C)hamp[0-9]+(\\s|$)\")\n","          re_pattern_cheer_Shamrock = re.compile(r\"(\\s|^)(s|S)hamrock[0-9]+(\\s|$)\")\n","          re_pattern_cheer_Slade = re.compile(r\"(\\s|^)(s|S)lade(c|C)heer[0-9]+(\\s|$)\")\n","          matches = re_pattern_cheer.finditer(message)\n","          matches_PogChamp = re_pattern_cheer_PogChamp.finditer(message)\n","          matches_Shamrock = re_pattern_cheer_Shamrock.finditer(message)\n","          matches_Slade = re_pattern_cheer_Slade.finditer(message)\n","\n","          for match in matches:\n","            found_cheer = True  \n","          for match in matches_PogChamp:\n","            found_PogChamp = True  \n","          for match in matches_Shamrock:\n","            found_Shamrock = True  \n","          for match in matches_Slade:\n","            found_Slade = True  \n","\n","          if found_cheer or found_PogChamp or found_Shamrock or found_Slade:\n","            with open(\"queue_file\", 'a') as queue:\n","              queue.write(f\"{user} {message}\")\n","      time.sleep(.1) #give some processing time back\n","\n","sock = socket.socket()\n","sock.connect((server, port))\n","sock.send(f\"PASS {token}\\n\".encode('utf-8'))\n","sock.send(f\"NICK {nickname}\\n\".encode('utf-8'))\n","sock.send(f\"JOIN {channel}\\n\".encode('utf-8'))\n","\n","hparams = create_hparams()\n","hparams.sampling_rate = 22050\n","hparams.max_decoder_steps = 3000 #set higher for longer messages\n","hparams.p_decoder_dropout = 0\n","hparams.p_attention_dropout = 0\n","hparams.gate_threshold = 0.2\n","\n","#Start up message receiving process\n","p1 = multiprocessing.Process(target=receive_resp, args=()) \n","p1.start()\n","time.sleep(2) #give some time for process to start up\n","\n","display(HTML(f'<span style=\"font-size:20px; color: #ff0000\">Listening for messages....</span>'))\n","\n","start_play_time = 0\n","current_time = time.time()\n","audio_length = 0\n","entry = \"\"\n","multi_audio = []\n","is_playing = False\n","\n","while True:\n","\n","  #Check if audio is still playing\n","  current_time = time.time()\n","  if ((current_time - start_play_time) > audio_length):\n","    is_playing = False\n","  else:\n","    is_playing = True\n","\n","  if not is_playing:\n","    #Check if entry in queue_file\n","    entry = \"\"\n","    with open(\"queue_file\", 'r') as queue:\n","      entry = queue.readline()\n","      if entry == \"\\n\":\n","        print(\"uh oh empty entry!\")\n","\n","    #Process text to audio\n","    if entry:\n","      entry_split = entry.split()\n","      user = entry_split.pop(0)\n","      message = \" \".join(entry_split)\n","      #print(f\"processed entry: {user} {message}\")\n","\n","      #remove 1st entry from queue file\n","      with open('queue_file', 'r') as fin:\n","          data = fin.read().splitlines(True)\n","      with open('queue_file', 'w') as fout:\n","          fout.truncate(0)\n","          fout.writelines(data[1:])\n","      \n","      speaker_lines = []\n","      line = []\n","      message_multi = \"\"\n","      multi_audio = []        \n","      #BREAK MESSAGE INTO VARIOUS SPEAKERS\n","      split_message = message.split()\n","\n","      while split_message:\n","        #check if input starts with speaker\n","        contains_speaker = False\n","        for s in speaker_list:\n","          if split_message[0] == f\"{s}:\":\n","            contains_speaker = True\n","\n","        if contains_speaker:        \n","          if line:\n","            speaker_lines.append(\" \".join(line))\n","            line = [split_message.pop(0)]\n","          else:\n","            line.append(split_message.pop(0))    \n","        else:\n","          #no speaker given or at beginning of message\n","          line.append(split_message.pop(0))\n","          if not split_message:\n","            #end of message, append last line\n","            speaker_lines.append(\" \".join(line))          \n","      #print(speaker_lines)       \n","\n","      if len(speaker_lines) > 1:    \n","        #Muliline, build audio for each appropriate line and piece back together\n","        message_multi = \"\"\n","        multi_audio = []\n","\n","        for phrase in speaker_lines:\n","          speaker = default_speaker\n","          for s in speaker_list:              \n","            if phrase.startswith(f\"{s}:\"):\n","              speaker = s\n","          #print(speaker)  \n","          phrase_stripped =  phrase.replace(f\"{speaker}:\", \"\")\n","          message_multi = message_multi + phrase_stripped\n","          #print(phrase)\n","\n","          audioout = synth_line(speaker, phrase_stripped)\n","\n","          #append audio                \n","          multi_audio.append(audioout)\n","\n","          #sf.write('out.wav', multi_audio, 22050) \n","\n","      else:\n","        #Single line, determine if speaker exists\n","        speaker = \"\"\n","        for s in speaker_list:              \n","          if speaker_lines[0].startswith(f\"{s}:\"):\n","              speaker = s\n","          print(speaker)  \n","        if speaker:\n","          out_message = message.replace(f\"{speaker}:\", \"\")   \n","          audioout = synth_line(speaker, out_message)              \n","        else:\n","          #single speaker, use default voice\n","          audioout = synth_line(default_speaker, message)                  \n","\n","        start_play_time = time.time()\n","        audio_segment = AudioSegment(\n","            audioout.tobytes(), \n","            frame_rate=22050,\n","            sample_width=audioout.dtype.itemsize, \n","            channels=1\n","        )\n","        audio_length = audio_segment.duration_seconds\n","\n","        if Autoplay_On:         \n","          clear_output()\n","          display(HTML(f'<span style=\"font-size:20px; color: #ff0000\">{user}: {message}</span>'))\n","          print()\n","          ipd.display(ipd.Audio(audioout, rate=hparams.sampling_rate, autoplay=True))\n","        else:\n","          clear_output()\n","          display(HTML(f'<span style=\"font-size:20px; color: #ff0000\">{user}: {message}</span>'))\n","          print()\n","          ipd.display(ipd.Audio(audioout, rate=hparams.sampling_rate, autoplay=False))\n","    \n","\n","      if multi_audio:\n","        #Stitch audio lines together into one line\n","        combined = AudioSegment.empty()\n","        second_of_silence = AudioSegment.silent(duration=1000) \n","\n","        for e, m in enumerate(multi_audio):\n","          audioout32 = np.float32(m)             \n","          sf.write(f'out{e}.wav', audioout32, 22050)\n","          audio_piece = AudioSegment.from_wav(f\"out{e}.wav\")\n","          combined += audio_piece + second_of_silence\n","\n","        audio_length = combined.duration_seconds\n","        combined_audio = combined.get_array_of_samples()\n","        combined_audio = np.array(combined_audio)\n","\n","        #Set timer so that queue doesn't overlap\n","        start_play_time = time.time()\n","\n","        if Autoplay_On:         \n","          clear_output()\n","          display(HTML(f'<span style=\"font-size:20px; color: #ff0000\">{user}: {message}</span>'))\n","          print()\n","          ipd.display(ipd.Audio(combined_audio, rate=hparams.sampling_rate, autoplay=True))\n","        else:\n","          clear_output()\n","          display(HTML(f'<span style=\"font-size:20px; color: #ff0000\">{user}: {message}</span>'))\n","          print()\n","          ipd.display(ipd.Audio(combined_audio, rate=hparams.sampling_rate, autoplay=False))\n","    "],"execution_count":null,"outputs":[]}]}